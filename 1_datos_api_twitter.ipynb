{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd01102b4f76c2802429a4ac4da36b234806d285894923ebc28dd83b617b861885a",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "# Aquí copia y pega tu bearer_token como string\n",
    "bearer_token = 'AAAAAAAAAAAAAAAAAAAAAATmNAEAAAAAHgDjutXTLigS%2Ffp%2Fr0S9IjMnet0%3DBWAdAMFQJwaJXzumNuL6rGW7imGci7C2sE761Mz9NfAJYmc6rI'\n",
    "headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)}\n",
    "\n",
    "# Toma como directorio de trabajo la ubicación del archivo (.ipynb) (necesitamos tener ahí mismo las bases de datos)\n",
    "pwd = os.getcwd()"
   ]
  },
  {
   "source": [
    "## Limpieza de Google Forms \n",
    "\n",
    "### Objetivo: Importar encuesta y limpiar: \n",
    "Archivo resultado:  1_colmex_limpio.csv.    Última descarga 09/04/2020 00:00 hrs 328 registros en total. 310 registros netos."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Importamos la base original\n",
    "original = pd.read_csv(pwd + \"/0_google_forms.csv\")\n",
    "# Duplicamos la base para no modificar la original\n",
    "colmex = original.copy()\n",
    "# Cambiamos el nombre de las columnas\n",
    "colmex = colmex.rename(columns={colmex.columns[0]: 'time',\n",
    "                        colmex.columns[1]: 'status',\n",
    "                        colmex.columns[2]: 'center',\n",
    "                        colmex.columns[3]: 'username',\n",
    "                        colmex.columns[4]: 'id'})\n",
    "# Seleccionamos las columnas relevantes\n",
    "colmex = colmex[[\"id\", \"username\",\"status\",\"center\"]]\n",
    "# Creamos dos diccionarios para mapear los nombres dic_status y dic_center\n",
    "dic_status = {'En la comunidad actualmente': 'current',\n",
    "    'Ex-alumno, ex-becario, ex-profesor, ex-administrativo': 'former'}\n",
    "dic_center = { \n",
    "    \"Centro de Estudios Económicos (CEE)\": \"CEE\",\n",
    "     \"Centro de Estudios Históricos (CEH)\": \"CEH\",\n",
    "     \"Centro de Estudios Internacionales (CEI)\":\"CEI\",\n",
    "     \"Centro de Estudios Económicos (CEE)\" : \"CEE\",\n",
    "     \"Centro de Estudios Lingüísticos y Literarios (CELL)\" : \"CELL\",\n",
    "     \"Centro de Estudios de Asia y África (CEAA)\" : \"CEAA\",\n",
    "     \"Centro de Estudios Demográficos, Urbanos y Ambientales (CEDUA)\" : \"CEDUA\",\n",
    "     \"Centro de Estudios Sociológicos (CES)\" : \"CES\",\n",
    "     \"Biblioteca/Administrativo/Idiomas\" : \"ADM\"}\n",
    "# Remplazamos los valores de acuerdo a los diccionarios\n",
    "colmex=colmex.replace({\"status\": dic_status})\n",
    "colmex=colmex.replace({\"center\": dic_center})\n",
    "# Quitamos IDs duplicados\n",
    "colmex = colmex.drop_duplicates(subset=['id'])\n",
    "# Quitamos usernames mal escritos con @ al inicio\n",
    "colmex['username'] = colmex['username'].str.replace('@','')\n",
    "colmex.reset_index(drop=True)\n",
    "# Guardamos la base limpia\n",
    "colmex.to_csv (pwd + \"/1_colmex_limpio.csv\", index = False)\n",
    "colmex.info()"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "## Base limpia y funciones adicionales\n",
    "\n",
    "### Primer mitad \\[0:120\\] Diego\n",
    "### Segunda mitad \\[120:237\\] Emilio"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llamamos la base limpia, tiene 307 observaciones:\n",
    "colmex_original = pd.read_csv(pwd + \"/1_colmex_limpio.csv\")\n",
    "# Respaldamos la base original por si haremos cortes o updtes\n",
    "colmex = colmex_original\n",
    "colmex"
   ]
  },
  {
   "source": [
    "### Una función que nos da el índice en Colmex al escribir el usuario"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_colmex(username):\n",
    "    try:\n",
    "        index = colmex_original['username'].loc[lambda x: x==username].index[0]\n",
    "        print(\"El index en Colmex de \" + username + \" es \" + str(index))\n",
    "    except IndexError:\n",
    "        print (\"El usuario no está en Colmex\")"
   ]
  },
  {
   "source": [
    "### Una función que nos da el usuario y ID en Colmex al escribir el índice"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def username_colmex(index):\n",
    "    try:\n",
    "        id = colmex_original['id'].iloc[index]\n",
    "        user = colmex_original['username'].iloc[index]\n",
    "        print(\"El username en Colmex del índice \" + str(index) + \" es \" + user + \", ID: \" + str(id))\n",
    "    except IndexError:\n",
    "        print (\"El índice no está en Colmex\")"
   ]
  },
  {
   "source": [
    "### Probamos las funciones"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_colmex(\"Alextuto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "username_colmex(286)"
   ]
  },
  {
   "source": [
    "## Descarga de datos desde API Twitter"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un data frame vacío con las columnas finales\n",
    "df = pd.DataFrame(columns=['id','username','status','center','target','t_username','t_name'])\n",
    "# Cargamos el df a actualizar\n",
    "# df = pd.read_csv(pwd +\"/2_red_colmex_completa.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos un for loop maravilloso lleno de if's y while's internos y vamos llenado la base df\n",
    "# Vamos a iterar para todas las observaciones de colmex\n",
    "for num in range(colmex.shape[0]):\n",
    "    id =  colmex['id'].iloc[num] # Guardamos el id en una variable\n",
    "    url = f'https://api.twitter.com/2/users/{id}/following?max_results=1000'  # Generamos el URL del request de 1000 following\n",
    "    req = requests.get(url,headers=headers) # Hacemos el request\n",
    "    time.sleep(65) # Esperamos 70 segundos porque podemos hacer 15 request en una ventana de 15 minutos\n",
    "    if 'data' in req.json().keys(): # Revisamos que sea un request exitoso (cuando son cuentas privadas marca error)\n",
    "        following = req.json() # Pasamos el json object a un diccionario de Python\n",
    "        data = dict()\n",
    "        data['data'] = []\n",
    "        data['data'].extend(following['data'])  # Pasamos el diccionario a una lista con los datos\n",
    "        df_loop = pd.json_normalize(data, record_path =['data']) # Convertimos a un pandas dataframe con método normalize\n",
    "        df_loop = df_loop[['id', 'name', 'username']] # Nos quedamos con las columnas que nos interesan (por si hay extras)\n",
    "        df_loop = df_loop.rename(columns={\"id\": \"target\", # Cambiamos los nombres del target\n",
    "        \"name\":\"t_name\",\"username\":\"t_username\"})\n",
    "        df_loop[\"id\"]=colmex['id'].iloc[num] \n",
    "        df_loop[\"username\"]=colmex['username'].iloc[num]\n",
    "        df_loop[\"status\"]=colmex['status'].iloc[num]\n",
    "        df_loop[\"center\"]=colmex['center'].iloc[num]\n",
    "        df = df.append(df_loop, ignore_index = True)  # Hacemos append del dataframe que itera (df_loop) al dataframe principal (df)\n",
    "        while 'next_token' in following['meta']: # Si tiene más de 1,000 followings, revisamos el next_token en los metadatos\n",
    "            pag_num = following['meta']['next_token'] # Guardamos en next_token en la variable page_num\n",
    "            url=f'https://api.twitter.com/2/users/{id}/following?max_results=1000&pagination_token={pag_num}' \n",
    "            req = requests.get(url,headers=headers) # Hacemos nuevamente el request de la siguiente página\n",
    "            time.sleep(65) # Volvemos a esperar y se repite el proceso, el while se rompe cuando ya no haya un next_token\n",
    "            following = req.json()\n",
    "            data = dict()\n",
    "            data['data'] = []\n",
    "            data['data'].extend(following['data'])\n",
    "            df_loop = pd.json_normalize(data, record_path =['data'])\n",
    "            df_loop = df_loop.rename(columns={\"id\": \"target\",\n",
    "            \"name\":\"t_name\",\"username\":\"t_username\"})\n",
    "            df_loop[\"id\"]=colmex['id'].iloc[num]\n",
    "            df_loop[\"username\"]=colmex['username'].iloc[num]\n",
    "            df_loop[\"status\"]=colmex['status'].iloc[num]\n",
    "            df_loop[\"center\"]=colmex['center'].iloc[num]\n",
    "            df = df.append(df_loop, ignore_index = True)\n",
    "        else:\n",
    "            continue\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "source": [
    "## ¿Qué hacer si marca un error? Si no hay errores pasar a sección siguiente\n",
    "\n",
    "Hasta el momento nos hemos encontrado con dos tipos de error. \n",
    "- JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
    "- Gateway Timeout (Too many tries) o algo similar.\n",
    "\n",
    "Muy probablemente el error se generó con un usuario nuevo y no al recuperar páginas siguientes de un usuario. (Recordando que vamos bajando los datos de 1,000 en 1,000). Por tanto vamos a revisar en cuál nos quedamos y retomar la descarga a partir de ahí."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "    1. Revisamos hasta dónde avanzó el código y en qué usuario se quedó."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "source": [
    "    2. Ubicamos el índice del usuario que tuvo el problema \n",
    "Probablemente el usuario que tuvo problema fue el siguiente al último guardado en df"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Índice de último usuario en df\n",
    "index_colmex(df.iloc[-1,1])"
   ]
  },
  {
   "source": [
    "    3. Nos quedamos con el resto de la base partiendo del usuario con problema\n",
    "\n",
    "Ejemplo: El usuario con índice 30 es el último en df, probablemente el 31 marcó el error, comenzamos de nuevo a partir de él."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colmex = colmex[280:310]\n",
    "colmex"
   ]
  },
  {
   "source": [
    "    4. Esperamos unos 20 min (por si es saturación de Twitter) y volvemos a correr el for{} con la nueva base\n",
    "\n",
    "Este nuevo for{} reanuda a partir del usuario con error y añade a df donde se quedó.  \n",
    "\n",
    "**Importante no remplazar o modificar la base df porque ahí están todos los datos buenos hasta antes del error.**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num in range(colmex.shape[0]):\n",
    "    id =  colmex['id'].iloc[num] # Guardamos el id en una variable\n",
    "    url = f'https://api.twitter.com/2/users/{id}/following?max_results=1000'  # Generamos el URL del request de 1000 following\n",
    "    req = requests.get(url,headers=headers) # Hacemos el request\n",
    "    time.sleep(70) # Esperamos 70 segundos porque podemos hacer 15 request en una ventana de 15 minutos\n",
    "    if 'data' in req.json().keys(): # Revisamos que sea un request exitoso (cuando son cuentas privadas marca error)\n",
    "        following = req.json() # Pasamos el json object a un diccionario de Python\n",
    "        data = dict()\n",
    "        data['data'] = []\n",
    "        data['data'].extend(following['data'])  # Pasamos el diccionario a una lista con los datos\n",
    "        df_loop = pd.json_normalize(data, record_path =['data']) # Convertimos a un pandas dataframe con método normalize\n",
    "        df_loop = df_loop[['id', 'name', 'username']] # Nos quedamos con las columnas que nos interesan (por si hay extras)\n",
    "        df_loop = df_loop.rename(columns={\"id\": \"target\", # Cambiamos los nombres del target\n",
    "        \"name\":\"t_name\",\"username\":\"t_username\"})\n",
    "        df_loop[\"id\"]=colmex['id'].iloc[num] \n",
    "        df_loop[\"username\"]=colmex['username'].iloc[num]\n",
    "        df_loop[\"status\"]=colmex['status'].iloc[num]\n",
    "        df_loop[\"center\"]=colmex['center'].iloc[num]\n",
    "        df = df.append(df_loop, ignore_index = True)  # Hacemos append del dataframe que itera (df_loop) al dataframe principal (df)\n",
    "        while 'next_token' in following['meta']: # Si tiene más de 1,000 followings, revisamos el next_token en los metadatos\n",
    "            pag_num = following['meta']['next_token'] # Guardamos en next_token en la variable page_num\n",
    "            url=f'https://api.twitter.com/2/users/{id}/following?max_results=1000&pagination_token={pag_num}' \n",
    "            req = requests.get(url,headers=headers) # Hacemos nuevamente el request de la siguiente página\n",
    "            time.sleep(70) # Volvemos a esperar y se repite el proceso, el while se rompe cuando ya no haya un next_token\n",
    "            following = req.json()\n",
    "            data = dict()\n",
    "            data['data'] = []\n",
    "            data['data'].extend(following['data'])\n",
    "            df_loop = pd.json_normalize(data, record_path =['data'])\n",
    "            df_loop = df_loop.rename(columns={\"id\": \"target\",\n",
    "            \"name\":\"t_name\",\"username\":\"t_username\"})\n",
    "            df_loop[\"id\"]=colmex['id'].iloc[num]\n",
    "            df_loop[\"username\"]=colmex['username'].iloc[num]\n",
    "            df_loop[\"status\"]=colmex['status'].iloc[num]\n",
    "            df_loop[\"center\"]=colmex['center'].iloc[num]\n",
    "            df = df.append(df_loop, ignore_index = True)\n",
    "        else:\n",
    "            continue\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "source": [
    "Si hay nuevamente un error, repetir el proceso.  \n",
    "Quizá valdría la pena revisar el perfil del usuario que marca error a ver si tiene algo en especial.  \n",
    "Si de plano no funciona, nos lo saltamos (subset de nuevo a Colmex a partir del siguiente id)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Revisamos que llegamos al final de nuestra parte de **colmex** y guardamos la base"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colmex.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El ID debe coincidir con el último usuario en nuestra parte de colmex\n",
    "index_colmex(df.iloc[-1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos la base como csv \n",
    "# Cambiar terminación diego / emilio para separarlas y ubicarlas\n",
    "df.to_csv (pwd + \"/2_red_colmex_completa.csv\", index = False)"
   ]
  },
  {
   "source": [
    "### Confirmación adicional de que todo está bien, revisar el número de following en nuestra base y en Twitter "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_colmex = pd.read_csv(pwd +\"/2_red_colmex_completa.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_colmex.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función que nos dice cuántos following tiene un usuario\n",
    "def following(username):\n",
    "    summary = red_colmex.groupby('username').agg(following=('target', 'size')).reset_index().sort_values(['following'], ascending=False)\n",
    "    return summary.loc[summary['username'] == username]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revisamos cuántos following tiene MGF91\n",
    "following(\"MGF91\")\n",
    "# En nuestra base tiene 3539 y viendo en Twitter sigue a 3541 \n",
    "# (Entre la recolección y ahorita siguió a 2 nuevas personas, ni pedo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_colmex.username.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Listo :D\")"
   ]
  },
  {
   "source": [
    "## Base Diego y Emilio"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape\n",
    "#df[df.username == 'cabrowns']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[df.username == 'cabrowns']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diego=df[0:110556]\n",
    "df_diego.to_csv (pwd + \"/2_red_colmex_diego.csv\", index = False)\n",
    "df_emilio=df[110556:224176]\n",
    "df_emilio.to_csv (pwd + \"/2_red_colmex_emilio.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}